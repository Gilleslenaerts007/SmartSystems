{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: Average length of real versus predicted value; minimize the mean squared error (cost function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling Best Practice:\n",
    "- use cost function to fit the model  \n",
    "- Develop multiple models  \n",
    "- Compare results and choose best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other model Metrics:\n",
    "- Sum of Squared Error (SSE)  \n",
    "- Total Sum of Squares (TSS)  \n",
    "- Correlation Coefficient (RR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Linear Regression:  \n",
    "- fitting involves minimizing cost function (slow)\n",
    "- model has few parameters (memory efficient)  \n",
    "- prediction involves calculation (fast)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Syntax\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "LR = LR.fit(X_train, y_train)\n",
    "y_predict = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling!  \n",
    "Transformation of Data distributions (features and predicted data are often skewed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax of common function that take inputs and output a more \"gaussian\" looking curve\n",
    "from numpy import log, log1p\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some transformations:  \n",
    "- Feature type is continuous (numerical values) => Standard scaling, min-max scaling  \n",
    "- Nominal (categorical, unordered features (True or False) => One-hot encoding (0,1)  \n",
    "- Ordinal (categorical, ordered features (movie ratings) => Ordinal encoding (0,1,2,3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2d398bdbbf70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Syntax for some transformations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_dummies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Syntax for some transformations\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pandas import get_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another preprocessing trick we can apply is to create new features out of the ones we already have (for instance fitting a polynomial) The resulting algorithm is still linear, since the outcome is still a linear combination of the features  \n",
    "Non-linear relationship between one feature and the other does not make the algorithm non-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include variable interactions as a new feature (get creative in creating additional features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for polynomial Features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polyFeat = PolynomialFeatures(degree=2)\n",
    "polyFeat = PolyFeat.fit(X_data)\n",
    "X_poly = polyFeat.transform(X_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
